% CVPR 2023 Paper Template
% based on the CVPR template provided by Ming-Ming Cheng (https://github.com/MCG-NKU/CVPR_Template)
% modified and extended by Stefan Roth (stefan.roth@NOSPAMtu-darmstadt.de)
\documentclass[10pt,twocolumn,letterpaper]{article}
\usepackage[T1]{fontenc}

%%%%%%%%% PAPER TYPE  - PLEASE UPDATE FOR FINAL VERSION
% \usepackage[review]{cvpr}      % To produce the REVIEW version
\usepackage{cvpr}              % To produce the CAMERA-READY version
%\usepackage[pagenumbers]{cvpr} % To force page numbers, e.g. for an arXiv version

% Include other packages here, before hyperref.
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{graphics}

% It is strongly recommended to use hyperref, especially for the review version.
% hyperref with option pagebackref eases the reviewers' job.
% Please disable hyperref *only* if you encounter grave issues, e.g. with the
% file validation for the camera-ready version.
%
% If you comment hyperref and then uncomment it, you should delete
% ReviewTempalte.aux before re-running LaTeX.
% (Or just hit 'q' on the first LaTeX run, let it finish, and you
%  should be clear).
\usepackage[pagebackref,breaklinks,colorlinks]{hyperref}


% Support for easy cross-referencing
\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}


%%%%%%%%% PAPER ID  - PLEASE UPDATE
\def\cvprPaperID{*****} % *** Enter the CVPR Paper ID here
\def\confName{CVPR}
\def\confYear{2023}


\begin{document}

%%%%%%%%% TITLE - PLEASE UPDATE
    \title{Programming Assignment 2: PoseRAC}

    \author{Bingnan Li\\
    2020533092\\
    {\tt\small libn@shanghaitech.edu.cn}
    }
    \maketitle

%%%%%%%%% ABSTRACT
    \begin{abstract}
        In this assignment, I explored the state-of-the-art repeat action counting algorithm {\bf PoseRAC} and tried to
        reproduce the results in the original paper.
        Then I proved the necessity of Transformer encoder by canceling the encoder part and using Fully-Connected Layer only.
        Moreover, I also tried to explore the relationship between counting performance and the number of encoder layers
        together with number of heads in the multi-head attention module.
        The results show that the performance of PoseRAC barely improves when the number of encoder layers increases from 1 to 8,
        but the model will crush when the number of encoder layers is larger than 8 in my training setting.
        Besides, the performance of PoseRAC is not sensitive to the number of heads in the multi-head attention module.
        Finally, I replaced the triplet margin loss with {\bf contrastive loss} and {\bf circle loss}, the results show that
        circle loss significantly boosts the model within 20 epoch, the evaluation metrics MAE and OBO improved from 0.2540 and 0.5395 to 0.2083 and 0.6053.
    \end{abstract}

%%%%%%%%% BODY TEXT


    \section{Introduction}
    \label{sec:intro}

    {\bf PoseRAC} is the state-of-the-art repeat action counting algorithm proposed by~\cite{yao2023poserac}.
    This model achieves tremendous success in the repeat action counting task and improves the performance of the previous
    state-of-the-art model by a large margin.
    The novelty of PoseRAC is the new annotation method.
    The traditional method will annotate the start and the end frame of an action, models are forced the regress the locations or indices
    of an action.
    However, PoseRAC turns the annotation into two salient frames which indicates the most representative points of an action.
    Then PoseRAC utilizes a keypoint extractor to transform the salient frames into a series of keypoint with 3D coordinates.
    This operation enormously reduces the amount of data need to process and improves the effectiveness of information because
    it only uses transformer encoder layer to get the embedding information and a single FC layer to classify the embedding.

%-------------------------------------------------------------------------


    \section{Necessity of Transformer Encoder}
    \label{sec:necessity}

    In this section, I will prove the necessity of Transformer encoder by canceling the encoder part and using Fully-Connected Layer only.
    By the original implementation, the input of the model is a series of keypoint with 3D coordinates, the output of the model is the
    score of different salient frame of different actions.
    The keypoint data is fed into a transformer encoder layer and a fully-connected layer to get the final output.
    Since the transformer does not change the dimension of the input, I can directly cancel the transformer encoder layer and use
    a fully-connected layer to get the final output to explor how essential transformer is to the model.

    The comparison of the performance of PoseRAC with and without transformer encoder is shown in Table~\ref{tab:w/o transformer}.
    This result shows that the performance of PoseRAC is significantly degraded when the transformer encoder is canceled.
    Even the training loss (Binary Cross Entropy) drops to the same level of that of the original model, the evaluation metrics
    MAE and OBO are still much worse than the original model.

    This experiment proves that directly classifying the keypoint data with 3D coordinates (normalized to $[0,1]$) cannot
    fit the test data distribution and the transformer encoder embeds the keypoint information into a feature space that
    are highly separable and truly represents the common features for the same action.

    \begin{table}
        \centering
        \begin{tabular}[H]{c c c}
            Model           & MAE    & OBO    \\
            \hline
            \hline
            PoseRAC         & 0.2540 & 0.5395 \\
            \hline
            w/o Transformer & 0.9928 & 0.0263 \\
        \end{tabular}
        \caption{The performance of PoseRAC with and without transformer encoder.}
        \label{tab:w/o transformer}
    \end{table}

    \paragraph{Training Setting:}
    \begin{itemize}
        \item lr: $0.00025$
        \item $\alpha$: $0.01$
        \item epoch: $20$
    \end{itemize}

%-------------------------------------------------------------------------


    \section{Impact on the Number of Encoder Layers and Number of Heads}
    \label{sec:num_layers_num_heads}
    In this section, I will explore the relationship between counting performance and the number of encoder layers
    together with number of heads in the multi-head attention module.
    In the original implementation, the number of encoder layers is 6 and the number of heads is 9.
    Intuitively, the more encoder layers and heads, the more information the model can capture.
    So, I set the number of encoder layers to be (1, 2, 4, 6, 8, 10, 12) and the number of heads to be (1, 3, 9, 11, 33).

    Moreover, in order to guarantee the convergence of models, I set the max training epoch from 20 to 50 and test the models
    which leads to the lowest validation loss.

    The experiment results are shown in Table~\ref{tab:MAE} and TAble~\ref{tab:OBO} and the corresponding curve is shown in Figure~\ref{fig:MAE_curve} and Figure~\ref{fig:OBO_curve}.
    

    \begin{table}
        \centering
        \resizebox{8cm}{!}{
            \begin{tabular}[b]{c c c c c c c c}
                \hline
                head/layer & 1 & 2 & 4 & 6 & 8 & $\geq 10$ \\
                \hline
                1 & 0.267 & 0.256 & 0.245 & 0.258 & 0.252 & -\\
                3 & 0.294 & 0.272 & 0.238 & 0.248 & 0.264 & -\\
                9 & 0.275 & 0.267 & 0.255 & 0.244 & 0.246 & -\\
                11 & 0.280 & 0.242 & 0.229 & 0.232 & 0.256 & -\\
                33 & 0.287 & 0.262 & 0.253 & 0.275 & 0.225 & -\\
                \hline
            \end{tabular}
        }
        \caption{MAE of different parameter combinations}
        \label{tab:MAE}
        \resizebox{8cm}{!}{
            \begin{tabular}[b]{c c c c c c c c}
                \hline
                head/layer & 1 & 2 & 4 & 6 & 8 & $\geq 10$ \\
                \hline
                1  & 0.467& 0.526& 0.507& 0.507& 0.533& -\\
                3  & 0.467& 0.507& 0.539& 0.533& 0.480& -\\
                9  & 0.487& 0.474& 0.513& 0.474& 0.533& -\\
                11 & 0.474& 0.526& 0.546& 0.520& 0.461& -\\
                33 & 0.461& 0.487& 0.526& 0.474& 0.513& -\\
                \hline
            \end{tabular}
        }
        \caption{OBO of different parameter combinations}
        \label{tab:OBO}
    \end{table}
    

    \begin{figure}[b]
        \centering
        \includegraphics[width=0.35\textwidth]{img/MAE_curve.png}
        \caption{MAE curve of different number of encoder layers and number of heads.}
        \label{fig:MAE_curve}
        \includegraphics[width=0.35\textwidth]{img/OBO_curve.png}
        \caption{OBO curve of different number of encoder layers and number of heads.}
        \label{fig:OBO_curve}
    \end{figure}

    From the experiment results, I figured out that the performance of PoseRAC can not be further improved either by increasing num of heads or num of encoder layers and 
    the model will even crush if the num of layers increases larger than 10.

    \paragraph{Training Setting}
    \begin{itemize}
        \item lr: $0.00025$
        \item $\alpha$: $0.01$
        \item epoch: $50$
    \end{itemize}

    \section{Impact on Training Loss}
    In this section, I will explore the effect of training loss on the performance of models.
    Given that in Section~\ref{sec:num_layers_num_heads}, I discovered that the number of heads and the number of layers can not boost the model even further, which means
    the transformer encoder is capable enough to embed the keypoint information even with 1 layer and 1 heads, so I try to modify the training loss and check its effect.

    In the original paper, the training loss consists of two parts: TripletMarinLoss and BinaryCrossEntropyLoss. The former loss is used to push the embedding of different classes far enough while 
    keeping the pair in the same class as closely as possible and the latter loss is used to supervise the classification process.
    Since the BinaryCrossEntropyLoss is widely used in classification tasks and barely has improved modifications, our focus will be the modifications of TripletMarinLoss.

    In detail, I replaced TripletMarinLoss with ContrastiveLoss~\cite{hadsell2006dimensionality} and CircleLoss~\cite{sun2020circle}, the results are shown in Table~\ref{tab:Loss}.
    The results show that CircleLoss tremendously improved the model in both MAE and OBO while ContrastiveLoss get a slight decrease in MAE but an enormous decrease in OBO compared with TripletMarinLoss.


    \begin{table}
        \centering
        \begin{tabular}[pos]{c c c}
            \hline
            Loss/Metrics & MAE & OBO\\
            \hline
            ContrastiveLoss & 0.2550 & 0.4737\\
            TripletMarinLoss & 0.2540 & 0.5395\\
            CircleLoss & {\bf 0.2083} & {\bf 0.6053}\\
            \hline
        \end{tabular}
        \caption{Impact of Losses on performance}
        \label{tab:Loss}
    \end{table}

    \paragraph{Training Setting}
    \begin{itemize}
        \item lr: $0.00025$
        \item $\alpha$: 0.01
        \item epoch: 20
        \item heads: 9
        \item layers: 6
        \item circle\_loss:
        \begin{itemize}
            \item m: 0.4
            \item $\gamma$:80
        \end{itemize}
        \item contrastive\_loss:
        \begin{itemize}
            \item pos\_margin=0
            \item neg\_margin=1
        \end{itemize}
    \end{itemize}

    \section{Shortcut of PoseRAC}
    Even PoseRAC has achieved success in PAC, but it still has many shortcut in model design:
    
    PoseRAC output is $\#\{class\}$-length vector, in the original setting, $0$ represents salient frame 2 and $1$ represents salient frame 1, but the annotation for 
    salient 2 is an all-zero vector with size $\#\{class\}$. In other words, PoseRAC can not discriminate the salient frames of different classes since no matter what classes the salient 2 belongs to, the corresponding annotate is always an all-zero vector.
    The way the author addresses this is a kind of brute force: he traverses all action classes and performs the counting process and takes the highest class result as the final result.
    But if the number of classes increases from 8 (original setting) to 100 or even 1000, the computing performance may drop and can not even run in real time.
%%%%%%%%% REFERENCES
    {\small
    \bibliographystyle{ieee_fullname}
    \bibliography{egbib}
    }

\end{document}
